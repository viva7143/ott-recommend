{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e68d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693c90e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let $F_n$ be the $n$-th Fibonacci number, with $F_1 = 1, F_2 = 1, F_3 = 2$.\n",
      "We want to calculate the sum of exponentials of the first 3 Fibonacci numbers, which is\n",
      "$$ e^{F_1} + e^{F_2} + e^{F_3} = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2 $$\n",
      "We can approximate $e \\approx 2.71828$, so\n",
      "$$ 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.38905 \\approx 12.82561 $$\n",
      "Alternatively,\n",
      "$$ 2e + e^2 = e(2+e) \\approx 2.71828(2 + 2.71828) = 2.71828(4.71828) \\approx 12.82561 $$\n",
      "\n",
      "The sum of the exponentials of the first 3 Fibonacci numbers is $e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{2e+e^2}$\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Calculate the sum of exponentials of first 3 Fibonacci numbers\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972701c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = '''You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) - Takes a word as input and returns ASCII INT values of characters in the word as a list.\n",
    "2. int_list_to_exponential_sum(list) - Takes a list of integers and returns the sum of exponentials of those integers.\n",
    "3. fibonacci_numbers(int) - Takes an integer, like 6, and returns the first 6 integers in a Fibonacci series as a list.\n",
    "\n",
    "DO NOT include multiple responses. Give ONE response at a time. DO NOT compute anything yourself.'''\n",
    "\"\"\"You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def strings_to_chars_to_int(string):\n",
    "    return [ord(char) for char in string]\n",
    "\n",
    "def int_list_to_exponential_sum(int_list):\n",
    "    int_list = eval(int_list)\n",
    "    return sum(math.exp(i) for i in int_list)\n",
    "\n",
    "def fibonacci_numbers(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    fib_sequence = [0, 1]\n",
    "    for _ in range(2, n):\n",
    "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
    "    return fib_sequence[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69444660",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.text.strip()\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fe45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, function_info = response_text.split(\":\", 1)\n",
    "_, function_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaabaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "\n",
    "func_name, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_caller(func_name, params):\n",
    "    \"\"\"Simple function caller that maps function names to actual functions\"\"\"\n",
    "    function_map = {\n",
    "        \"strings_to_chars_to_int\": strings_to_chars_to_int,\n",
    "        \"int_list_to_exponential_sum\": int_list_to_exponential_sum,\n",
    "        \"fibonacci_numbers\": fibonacci_numbers\n",
    "    }\n",
    "    \n",
    "    if func_name in function_map:\n",
    "        return function_map[func_name](params)\n",
    "    else:\n",
    "        return f\"Function {func_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_result = function_caller(func_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a739c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = '''You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) - Takes a word as input and returns ASCII INT values of characters in the word as a list.\n",
    "2. int_list_to_exponential_sum(list) - Takes a list of integers and returns the sum of exponentials of those integers.\n",
    "3. fibonacci_numbers(int) - Takes an integer, like 6, and returns the first 6 integers in a Fibonacci series as a list.\n",
    "\n",
    "DO NOT include multiple responses. Give ONE response at a time. DO NOT compute anything yourself.'''\n",
    "\"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.text.strip()\n",
    "_, function_info = response_text.split(\":\", 1)\n",
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "iteration_result = function_caller(func_name, params)\n",
    "iteration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = '''You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) - Takes a word as input and returns ASCII INT values of characters in the word as a list.\n",
    "2. int_list_to_exponential_sum(list) - Takes a list of integers and returns the sum of exponentials of those integers.\n",
    "3. fibonacci_numbers(int) - Takes an integer, like 6, and returns the first 6 integers in a Fibonacci series as a list.\n",
    "\n",
    "DO NOT include multiple responses. Give ONE response at a time. DO NOT compute anything yourself.'''\n",
    "\"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called strings_to_chars_to_int with TSAI parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "iteration_2 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\\n\\n{iteration_2}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "iteration_response = []\n",
    "\n",
    "system_prompt = '''You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) - Takes a word as input and returns ASCII INT values of characters in the word as a list.\n",
    "2. int_list_to_exponential_sum(list) - Takes a list of integers and returns the sum of exponentials of those integers.\n",
    "3. fibonacci_numbers(int) - Takes an integer, like 6, and returns the first 6 integers in a Fibonacci series as a list.\n",
    "\n",
    "DO NOT include multiple responses. Give ONE response at a time. DO NOT compute anything yourself.'''\n",
    "\"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(iteration_response)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    iteration_response.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4845ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "iteration_response = []\n",
    "\n",
    "system_prompt =  \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(iteration_response)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    iteration_response.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import google.generativeai as genai\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Local API for fetching OTT recommendations\n",
    "LOCAL_API_URL = \"http://127.0.0.1:5000/recommend\"\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     contents=\"Calculate the sum of exponentials of first 3 Fibonacci numbers\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ott_platform(query):\n",
    "    \"\"\"Extracts OTT platform from query and returns standardized name.\"\"\"\n",
    "    ott_platforms = {\n",
    "        \"netflix\": \"Netflix\",\n",
    "        \"amazon prime\": \"Amazon Prime Video\",\n",
    "        \"hulu\": \"Hulu\",\n",
    "        \"disney+\": \"Disney+\",\n",
    "        \"hbo max\": \"HBO Max\"\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    for key, platform in ott_platforms.items():\n",
    "        if key in query_lower:\n",
    "            return platform\n",
    "\n",
    "    return \"Netflix\"  # Default to Netflix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_recommendations(platform):\n",
    "    \"\"\"Calls local API to fetch top OTT series recommendations.\"\"\"\n",
    "    api_url = f\"{LOCAL_API_URL}?platform={platform.replace(' ', '%20')}\"\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"recommendations\", [])\n",
    "    \n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_recommendations(recommendations):\n",
    "    if not isinstance(recommendations, list):  # Ensure response is a list\n",
    "        return \"Error: Invalid recommendations format received.\"\n",
    "\n",
    "    if not recommendations:\n",
    "        return \"No recommendations found.\"\n",
    "\n",
    "    formatted_result = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"🎬 *{rec.get('title', 'Unknown')}* ({rec.get('rating', 'N/A')}⭐)\\n\"\n",
    "            f\"📖 {rec.get('description', 'No description available')}\\n\"\n",
    "            f\"🖼️ [Poster]({rec.get('poster', '#')})\"\n",
    "            for rec in recommendations if isinstance(rec, dict)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return formatted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_MAPPING = {\n",
    "    \"extract_ott_platform\": extract_ott_platform,\n",
    "    \"get_series_recommendations\": get_series_recommendations,\n",
    "    \"format_recommendations\": format_recommendations\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # Required for parsing JSON parameters\n",
    "\n",
    "def function_caller(func_name, params):\n",
    "    FUNCTION_MAPPING = {\n",
    "        \"extract_ott_platform\": extract_ott_platform,\n",
    "        \"get_series_recommendations\": get_series_recommendations,\n",
    "        \"format_recommendations\": format_recommendations\n",
    "    }\n",
    "\n",
    "    if func_name in FUNCTION_MAPPING:\n",
    "        # Convert params if needed\n",
    "        try:\n",
    "            parsed_params = json.loads(params)  # Convert string to list/dict if possible\n",
    "        except json.JSONDecodeError:\n",
    "            parsed_params = params  # Keep as string if not JSON formatted\n",
    "\n",
    "        return FUNCTION_MAPPING[func_name](parsed_params)\n",
    "    else:\n",
    "        return f\"Function {func_name} not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Platform: Netflix\n",
      "Raw Recommendations: [{'description': 'When a 13-year-old is accused of the murder of a classmate, his family, therapist and the detective in charge are all left asking: what really happened?', 'poster': 'https://image.tmdb.org/t/p/w200/tDHWWReefmOOjBCJZUck8cNwssk.jpg', 'rating': 7.8, 'title': 'Adolescence'}, {'description': 'Robin, Starfire, Raven, Beast Boy and Cyborg return in all-new, comedic adventures. They may be super heroes who save the world every day ... but somebody still has to do the laundry!', 'poster': 'https://image.tmdb.org/t/p/w200/udaLIJ6Na7GOHjvTlyP9JFPTccv.jpg', 'rating': 6.5, 'title': 'Teen Titans Go!'}, {'description': \"Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with his family. He spends most of his time involving his young grandson Morty in dangerous, outlandish adventures throughout space and alternate universes. Compounded with Morty's already unstable family life, these events cause Morty much distress at home and school.\", 'poster': 'https://image.tmdb.org/t/p/w200/gdIrmf2DdY5mgN6ycVP0XlzKzbE.jpg', 'rating': 8.687, 'title': 'Rick and Morty'}, {'description': 'A reality series that follows some of the most affluent women in the country as they enjoy the lavish lifestyle that only Beverly Hills can provide.', 'poster': 'https://image.tmdb.org/t/p/w200/gHZmEmtQzobW9PVdpGrYP7SU9RH.jpg', 'rating': 6.3, 'title': 'The Real Housewives of Beverly Hills'}, {'description': 'Raymond \"Red\" Reddington, one of the FBI\\'s most wanted fugitives, surrenders in person at FBI Headquarters in Washington, D.C. He claims that he and the FBI have the same interests: bringing down dangerous criminals and terrorists. In the last two decades, he\\'s made a list of criminals and terrorists that matter the most but the FBI cannot find because it does not know they exist. Reddington calls this \"The Blacklist\". Reddington will co-operate, but insists that he will speak only to Elizabeth Keen, a rookie FBI profiler.', 'poster': 'https://image.tmdb.org/t/p/w200/4HTfd1PhgFUenJxVuBDNdLmdr0c.jpg', 'rating': 7.632, 'title': 'The Blacklist'}]\n",
      "Formatted Recommendations:\n",
      " 🎬 *Adolescence* (7.8⭐)\n",
      "📖 When a 13-year-old is accused of the murder of a classmate, his family, therapist and the detective in charge are all left asking: what really happened?\n",
      "🖼️ [Poster](https://image.tmdb.org/t/p/w200/tDHWWReefmOOjBCJZUck8cNwssk.jpg)\n",
      "\n",
      "🎬 *Teen Titans Go!* (6.5⭐)\n",
      "📖 Robin, Starfire, Raven, Beast Boy and Cyborg return in all-new, comedic adventures. They may be super heroes who save the world every day ... but somebody still has to do the laundry!\n",
      "🖼️ [Poster](https://image.tmdb.org/t/p/w200/udaLIJ6Na7GOHjvTlyP9JFPTccv.jpg)\n",
      "\n",
      "🎬 *Rick and Morty* (8.687⭐)\n",
      "📖 Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with his family. He spends most of his time involving his young grandson Morty in dangerous, outlandish adventures throughout space and alternate universes. Compounded with Morty's already unstable family life, these events cause Morty much distress at home and school.\n",
      "🖼️ [Poster](https://image.tmdb.org/t/p/w200/gdIrmf2DdY5mgN6ycVP0XlzKzbE.jpg)\n",
      "\n",
      "🎬 *The Real Housewives of Beverly Hills* (6.3⭐)\n",
      "📖 A reality series that follows some of the most affluent women in the country as they enjoy the lavish lifestyle that only Beverly Hills can provide.\n",
      "🖼️ [Poster](https://image.tmdb.org/t/p/w200/gHZmEmtQzobW9PVdpGrYP7SU9RH.jpg)\n",
      "\n",
      "🎬 *The Blacklist* (7.632⭐)\n",
      "📖 Raymond \"Red\" Reddington, one of the FBI's most wanted fugitives, surrenders in person at FBI Headquarters in Washington, D.C. He claims that he and the FBI have the same interests: bringing down dangerous criminals and terrorists. In the last two decades, he's made a list of criminals and terrorists that matter the most but the FBI cannot find because it does not know they exist. Reddington calls this \"The Blacklist\". Reddington will co-operate, but insists that he will speak only to Elizabeth Keen, a rookie FBI profiler.\n",
      "🖼️ [Poster](https://image.tmdb.org/t/p/w200/4HTfd1PhgFUenJxVuBDNdLmdr0c.jpg)\n"
     ]
    }
   ],
   "source": [
    "query = \"I need something good to watch on Netflix\"\n",
    "platform = extract_ott_platform(query)\n",
    "print(\"Extracted Platform:\", platform)\n",
    "\n",
    "recommendations = get_series_recommendations(platform)\n",
    "print(\"Raw Recommendations:\", recommendations)\n",
    "\n",
    "formatted_result = format_recommendations(recommendations)\n",
    "print(\"Formatted Recommendations:\\n\", formatted_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "LLM Response: FUNCTION_CALL: extract_ott_platform|query\n",
      "  Result: Netflix\n",
      "\n",
      "--- Iteration 2 ---\n",
      "LLM Response: FUNCTION_CALL: get_series_recommendations|Netflix\n",
      "  Result: [{'description': 'When a 13-year-old is accused of the murder of a classmate, his family, therapist and the detective in charge are all left asking: what really happened?', 'poster': 'https://image.tmdb.org/t/p/w200/tDHWWReefmOOjBCJZUck8cNwssk.jpg', 'rating': 7.8, 'title': 'Adolescence'}, {'description': 'Robin, Starfire, Raven, Beast Boy and Cyborg return in all-new, comedic adventures. They may be super heroes who save the world every day ... but somebody still has to do the laundry!', 'poster': 'https://image.tmdb.org/t/p/w200/udaLIJ6Na7GOHjvTlyP9JFPTccv.jpg', 'rating': 6.5, 'title': 'Teen Titans Go!'}, {'description': \"Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with his family. He spends most of his time involving his young grandson Morty in dangerous, outlandish adventures throughout space and alternate universes. Compounded with Morty's already unstable family life, these events cause Morty much distress at home and school.\", 'poster': 'https://image.tmdb.org/t/p/w200/gdIrmf2DdY5mgN6ycVP0XlzKzbE.jpg', 'rating': 8.687, 'title': 'Rick and Morty'}, {'description': 'A reality series that follows some of the most affluent women in the country as they enjoy the lavish lifestyle that only Beverly Hills can provide.', 'poster': 'https://image.tmdb.org/t/p/w200/gHZmEmtQzobW9PVdpGrYP7SU9RH.jpg', 'rating': 6.3, 'title': 'The Real Housewives of Beverly Hills'}, {'description': 'Raymond \"Red\" Reddington, one of the FBI\\'s most wanted fugitives, surrenders in person at FBI Headquarters in Washington, D.C. He claims that he and the FBI have the same interests: bringing down dangerous criminals and terrorists. In the last two decades, he\\'s made a list of criminals and terrorists that matter the most but the FBI cannot find because it does not know they exist. Reddington calls this \"The Blacklist\". Reddington will co-operate, but insists that he will speak only to Elizabeth Keen, a rookie FBI profiler.', 'poster': 'https://image.tmdb.org/t/p/w200/4HTfd1PhgFUenJxVuBDNdLmdr0c.jpg', 'rating': 7.632, 'title': 'The Blacklist'}]\n",
      "\n",
      "--- Iteration 3 ---\n",
      "LLM Response: FUNCTION_CALL: format_recommendations|recommendations\n",
      "  Result: Error: Invalid recommendations format received.\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "history = []\n",
    "\n",
    "system_prompt = \"\"\"You are an OTT recommendation agent solving user queries in iterations. \n",
    "Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: extract_ott_platform|query\n",
    "2. FUNCTION_CALL: get_series_recommendations|platform\n",
    "3. FUNCTION_CALL: format_recommendations|recommendations\n",
    "4. FINAL_ANSWER: formatted_output\n",
    "\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "query = \"I need something good to watch on Netflix\"\n",
    "\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(history)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    history.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- Iteration 1 ---\n",
    "LLM Response: FUNCTION_CALL: extract_ott_platform|query\n",
    "  Result: Netflix\n",
    "\n",
    "--- Iteration 2 ---\n",
    "LLM Response: FUNCTION_CALL: get_series_recommendations|Netflix\n",
    "  Result: [{'description': 'When a 13-year-old is accused of the murder of a classmate, his family, therapist and the detective in charge are all left asking: what really happened?', 'poster': 'https://image.tmdb.org/t/p/w200/tDHWWReefmOOjBCJZUck8cNwssk.jpg', 'rating': 7.8, 'title': 'Adolescence'}, {'description': 'Robin, Starfire, Raven, Beast Boy and Cyborg return in all-new, comedic adventures. They may be super heroes who save the world every day ... but somebody still has to do the laundry!', 'poster': 'https://image.tmdb.org/t/p/w200/udaLIJ6Na7GOHjvTlyP9JFPTccv.jpg', 'rating': 6.5, 'title': 'Teen Titans Go!'}, {'description': \"Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with his family. He spends most of his time involving his young grandson Morty in dangerous, outlandish adventures throughout space and alternate universes. Compounded with Morty's already unstable family life, these events cause Morty much distress at home and school.\", 'poster': 'https://image.tmdb.org/t/p/w200/gdIrmf2DdY5mgN6ycVP0XlzKzbE.jpg', 'rating': 8.687, 'title': 'Rick and Morty'}, {'description': 'A reality series that follows some of the most affluent women in the country as they enjoy the lavish lifestyle that only Beverly Hills can provide.', 'poster': 'https://image.tmdb.org/t/p/w200/gHZmEmtQzobW9PVdpGrYP7SU9RH.jpg', 'rating': 6.3, 'title': 'The Real Housewives of Beverly Hills'}, {'description': 'Raymond \"Red\" Reddington, one of the FBI\\'s most wanted fugitives, surrenders in person at FBI Headquarters in Washington, D.C. He claims that he and the FBI have the same interests: bringing down dangerous criminals and terrorists. In the last two decades, he\\'s made a list of criminals and terrorists that matter the most but the FBI cannot find because it does not know they exist. Reddington calls this \"The Blacklist\". Reddington will co-operate, but insists that he will speak only to Elizabeth Keen, a rookie FBI profiler.', 'poster': 'https://image.tmdb.org/t/p/w200/4HTfd1PhgFUenJxVuBDNdLmdr0c.jpg', 'rating': 7.632, 'title': 'The Blacklist'}]\n",
    "\n",
    "--- Iteration 3 ---\n",
    "LLM Response: FUNCTION_CALL: format_recommendations|recommendations\n",
    "Formatted Recommendations:\n",
    " 🎬 *Adolescence* (7.8⭐)\n",
    "📖 When a 13-year-old is accused of the murder of a classmate, his family, therapist and the detective in charge are all left asking: what really happened?\n",
    "🖼️ [Poster](https://image.tmdb.org/t/p/w200/tDHWWReefmOOjBCJZUck8cNwssk.jpg)\n",
    "\n",
    "🎬 *Teen Titans Go!* (6.5⭐)\n",
    "📖 Robin, Starfire, Raven, Beast Boy and Cyborg return in all-new, comedic adventures. They may be super heroes who save the world every day ... but somebody still has to do the laundry!\n",
    "🖼️ [Poster](https://image.tmdb.org/t/p/w200/udaLIJ6Na7GOHjvTlyP9JFPTccv.jpg)\n",
    "\n",
    "🎬 *Rick and Morty* (8.687⭐)\n",
    "📖 Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with his family. He spends most of his time involving his young grandson Morty in dangerous, outlandish adventures throughout space and alternate universes. Compounded with Morty's already unstable family life, these events cause Morty much distress at home and school.\n",
    "🖼️ [Poster](https://image.tmdb.org/t/p/w200/gdIrmf2DdY5mgN6ycVP0XlzKzbE.jpg)\n",
    "\n",
    "🎬 *The Real Housewives of Beverly Hills* (6.3⭐)\n",
    "📖 A reality series that follows some of the most affluent women in the country as they enjoy the lavish lifestyle that only Beverly Hills can provide.\n",
    "🖼️ [Poster](https://image.tmdb.org/t/p/w200/gHZmEmtQzobW9PVdpGrYP7SU9RH.jpg)\n",
    "\n",
    "🎬 *The Blacklist* (7.632⭐)\n",
    "📖 Raymond \"Red\" Reddington, one of the FBI's most wanted fugitives, surrenders in person at FBI Headquarters in Washington, D.C. He claims that he and the FBI have the same interests: bringing down dangerous criminals and terrorists. In the last two decades, he's made a list of criminals and terrorists that matter the most but the FBI cannot find because it does not know they exist. Reddington calls this \"The Blacklist\". Reddington will co-operate, but insists that he will speak only to Elizabeth Keen, a rookie FBI profiler.\n",
    "🖼️ [Poster](https://image.tmdb.org/t/p/w200/4HTfd1PhgFUenJxVuBDNdLmdr0c.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
